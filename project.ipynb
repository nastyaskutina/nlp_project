{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настя Скутина и Юля Маркова (БКЛ182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.session()\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "morph_vocab = MorphVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://stihi.ru/poems/list.html?topic=all&type=selected&year=2020&month=01&day=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_links = []\n",
    "for x in range (1,11):\n",
    "    if x < 10:\n",
    "        n = '0' + str(x)\n",
    "    else:\n",
    "        n = str(x)\n",
    "    link_n = re.sub(r'&month=(\\d\\d)&', '&month='+n+'&', link)\n",
    "    month_links.append(link_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(link):\n",
    "    poem_links = []\n",
    "    page = session.get(link, headers={'User-Agent': ua.random}).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    for a in soup.find_all('a', {'class': 'poemlink'}):\n",
    "        raw_link = re.search(r'href=\"(.*)\">', str(a))\n",
    "        poem_links.append('https://stihi.ru' + raw_link.group(1))\n",
    "    clear_links = poem_links[:15] + poem_links[25:]\n",
    "    return clear_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = []\n",
    "for month in month_links:\n",
    "    all_links.extend(get_links(month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poems(link):\n",
    "        poems_dict = {}\n",
    "        page = session.get(link, headers={'User-Agent': ua.random}).text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        poems_dict['Text'] = soup.find('div', {'class': 'text'}).text\n",
    "        poems_dict['Title'] = soup.find('h1').text\n",
    "        poems_dict['Author'] = soup.find('div', {'class': 'titleauthor'}).text\n",
    "        return poems_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for link in all_links:\n",
    "    time.sleep(random.uniform(3.1, 7.2))\n",
    "    texts.append(get_poems(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_texts = []\n",
    "for text in texts:\n",
    "    text_texts.extend(text['Text'].split())\n",
    "len(text_texts) #показывает количество вхождений в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEMM_DICTIONARY = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_dict(lemm, idx):\n",
    "    if lemm in LEMM_DICTIONARY:\n",
    "        if idx not in LEMM_DICTIONARY[lemm]:\n",
    "            LEMM_DICTIONARY[lemm].append(idx)\n",
    "    else:\n",
    "        LEMM_DICTIONARY[lemm] = [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(sent, idx):\n",
    "    dic = {}\n",
    "    dic['raw_sent'] = sent\n",
    "    dic['lemm_sent'] = []\n",
    "    dic['meta_word'] = []\n",
    "    dic['pos_sent'] = []\n",
    "    doc = Doc(sent)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    lemm_list = []\n",
    "    \n",
    "    for toc in doc.tokens:\n",
    "        toc.lemmatize(morph_vocab)\n",
    "        if toc.pos != 'PUNCT':\n",
    "            pos = toc.pos\n",
    "            word = toc.text.lower()\n",
    "            lemm = toc.lemma\n",
    "            lemm_dict(lemm, idx)\n",
    "            dic['lemm_sent'].append(lemm)\n",
    "            dic['meta_word'].append((word, pos))\n",
    "            dic['pos_sent'].append(pos)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text_info, idx):\n",
    "    dic = {}\n",
    "    dic['Author'] = text_info['Author']\n",
    "    dic['Title'] = text_info['Title']\n",
    "    dic['TextwInfo'] = []\n",
    "    doc = Doc(text_info['Text'])\n",
    "    doc.segment(segmenter)\n",
    "    for sent in doc.sents:\n",
    "        dic['TextwInfo'].append(parse_sentence(sent.text, idx))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = []\n",
    "for idx, text in enumerate(texts):\n",
    "    processed_text = text_processing(text, idx)\n",
    "    CORPUS.append(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2lemm(word):\n",
    "    lemm_list = []\n",
    "    for item in morph.parse(word):\n",
    "        if item.normal_form not in lemm_list:\n",
    "            new_item = re.sub('ё', 'е', item.normal_form)\n",
    "            lemm_list.append(new_item)\n",
    "    return lemm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_search(word):\n",
    "    lemms = word2lemm(word)\n",
    "    lemm2text = {}\n",
    "    for lemm in lemms:\n",
    "        if lemm in LEMM_DICTIONARY:\n",
    "            lemm2text[lemm] = LEMM_DICTIONARY[lemm]\n",
    "    return lemm2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_wordform(sent, wordform, lemm):\n",
    "    word_idx = sent['lemm_sent'].index(lemm)\n",
    "    if wordform in sent['meta_word'][word_idx]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_pos(sent, pos, lemm):\n",
    "    word_idx = sent['lemm_sent'].index(lemm)\n",
    "    if pos in sent['meta_word'][word_idx]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_text(lemm, text_idx, wordform=None, pos=None):\n",
    "    TextwInfo = CORPUS[text_idx]['TextwInfo']\n",
    "    sent_list= []\n",
    "    for sent in TextwInfo:\n",
    "            if lemm in sent['lemm_sent']:\n",
    "                if wordform == None and pos == None:\n",
    "                    sent_list.append(sent['raw_sent'])\n",
    "                    \n",
    "                elif wordform == None and pos != None:\n",
    "                    if if_pos(sent, pos, lemm) == 1:\n",
    "                        sent_list.append(sent['raw_sent'])\n",
    "                        \n",
    "                elif wordform != None and pos == None:\n",
    "                    if if_wordform(sent, wordform, lemm) == 1:\n",
    "                        sent_list.append(sent['raw_sent'])\n",
    "                \n",
    "                else:\n",
    "                    if if_wordform(sent, wordform, lemm) == 1:\n",
    "                        if if_pos(sent, pos, lemm) == 1:\n",
    "                            sent_list.append(sent['raw_sent'])\n",
    "\n",
    "    return (sent_list, CORPUS[text_idx]['Title'], CORPUS[text_idx]['Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse1word(request):\n",
    "    wordform = re.search(r'\"(\\w*)\"', request)\n",
    "    pos = re.search(r'\\+(\\w*)', request)\n",
    "    if wordform == None:\n",
    "        if pos == None:\n",
    "            word = request\n",
    "        else:\n",
    "            pos = pos.group(1)\n",
    "            word = re.search(r'(\\w*)\\+', request).group(1)\n",
    "    else:\n",
    "        wordform = wordform.group(1)\n",
    "        word = wordform\n",
    "        if pos != None:\n",
    "            pos = pos.group(1)\n",
    "    \n",
    "    return word, wordform, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_1word(request):\n",
    "    word, wordform, pos = parse1word(request)\n",
    "    LemmwIdx = lemm_search(word)\n",
    "    if len(LemmwIdx) != 0:\n",
    "        for item in LemmwIdx:\n",
    "            lemm = item\n",
    "            none_check = 0\n",
    "            results = []\n",
    "            for text_idx in LemmwIdx[item]:\n",
    "                sentence = word_in_text(lemm, text_idx, wordform=wordform, pos=pos)\n",
    "                if len(sentence[0]) != 0:\n",
    "                    none_check = 1\n",
    "                    results.append(sentence)\n",
    "            if none_check == 0:\n",
    "                print('Не нашлось :(')\n",
    "            else:\n",
    "                return results\n",
    "\n",
    "    else:\n",
    "        print('Не нашлось :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pos(request):\n",
    "    results = []\n",
    "    for text in CORPUS:\n",
    "        suit_sents = []\n",
    "        for sent in text['TextwInfo']:\n",
    "            if request in ' '.join(sent['pos_sent']):\n",
    "                suit_sents.append(sent['raw_sent'])\n",
    "        if len(suit_sents) != 0:\n",
    "            results.append((suit_sents, text['Title'], text['Author']))\n",
    "    if len(results) != 0:\n",
    "        return results\n",
    "    else:\n",
    "        print('sorry there is no such pos sequence in corpus :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_word_in_ngrm(req_word):\n",
    "    wordform = re.search(r'\"(\\w*)\"', req_word)\n",
    "    pos = re.search(r'[A-Z]+', req_word)\n",
    "    if wordform == None:\n",
    "        if pos == None:\n",
    "            word = req_word\n",
    "        else:\n",
    "            pos = pos.group(0)\n",
    "            word = re.search(r'(\\w*)\\+', req_word)\n",
    "            if word != None:\n",
    "                word = word.group(1)\n",
    "    else:\n",
    "        wordform = wordform.group(1)\n",
    "        word = wordform\n",
    "        if pos != None:\n",
    "            pos = pos.group(0)\n",
    "    \n",
    "    return word, wordform, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ngrm(request):\n",
    "    words = request.split()\n",
    "    parsed_words = []\n",
    "    for word in words:\n",
    "        parsed_word = parse_word_in_ngrm(word)\n",
    "        parsed_words.append(parsed_word)\n",
    "    return parsed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(word1, word2, n=1):\n",
    "    results = []\n",
    "    for lemm in word1['lemms']:\n",
    "        for text_idx in word1['lemms'][lemm]:\n",
    "            sent_list = []\n",
    "            for sent in CORPUS[text_idx]['TextwInfo']:\n",
    "                if lemm in sent['lemm_sent']:\n",
    "                    if check_word(sent, word1, sent['lemm_sent'].index(lemm)) == 1:\n",
    "                        word_idx = sent['lemm_sent'].index(lemm) + n\n",
    "                        if check_word(sent, word2, word_idx) == 1:\n",
    "                            sent_list.append(sent['raw_sent'])\n",
    "            if len(sent_list) != 0:\n",
    "                results.append((sent_list, CORPUS[text_idx]['Title'], CORPUS[text_idx]['Author']))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word(sent, word_info, word_idx):\n",
    "    lemms = word_info['lemms']\n",
    "    wordform = word_info['wordform']\n",
    "    pos = word_info['pos']\n",
    "    check = 0\n",
    "    if -1 < word_idx < len(sent['lemm_sent']):\n",
    "        if lemms == None or sent['lemm_sent'][word_idx] in lemms:\n",
    "            if wordform == None or wordform == sent['meta_word'][word_idx][0]:\n",
    "                if pos == None or pos == sent['meta_word'][word_idx][1]:\n",
    "                    check = 1\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bgrm(request):\n",
    "    bgrm = parse_ngrm(request)\n",
    "    words_inf = []\n",
    "    for word in bgrm:\n",
    "        word_inf = {}\n",
    "        word_inf['wordform'] = word[1]\n",
    "        word_inf['pos'] = word[2]\n",
    "        if word[0]:\n",
    "            word_inf['lemms'] = lemm_search(word[0])\n",
    "        else:\n",
    "            word_inf['lemms'] = None\n",
    "        words_inf.append(word_inf)\n",
    "    if words_inf[0]['lemms'] != None:\n",
    "        results = get_sents(words_inf[0], words_inf[1], 1)\n",
    "    else:\n",
    "        results = get_sents(words_inf[1], words_inf[0], -1)\n",
    "    if len(results) != 0:\n",
    "        return results\n",
    "    else:\n",
    "        print('Не нашлось :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_search(request):\n",
    "    print('\\n\\n')\n",
    "    if ' ' not in request:\n",
    "        results = search_1word(request)\n",
    "    else:\n",
    "        if request == request.upper():\n",
    "            results = search_pos(request)\n",
    "        else:\n",
    "            results = search_bgrm(request)\n",
    "    if results != None:\n",
    "        for result in results:\n",
    "            for sent in result[0]:\n",
    "                print('\"'+result[1]+'\" -', result[2])\n",
    "                print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите слово или словосочетание:\n",
      "смерть\n",
      "\n",
      "\n",
      "\n",
      "\"Рубище\" - Владислав Савенко\n",
      "Этим ветрам насвистывать\n",
      "Музыку горних сфер,\n",
      "Что словно смерть неистова,\n",
      "Оголена  как нерв. \n",
      "\n",
      "\"В дорогу\" - Екатерина Кычкина\n",
      "Я люблю и буду любить всегда,\n",
      "Даже когда стану совсем седа,\n",
      "Ведь любовь - за рамками круговерти,\n",
      "Неподвластна времени, как и смерти,\n",
      "Она свет, разлитый в моей груди,\n",
      "Говорящий: \"Всё хорошо, иди\". \n",
      "\n",
      "\"Ветер на планете\" - Мария Махова\n",
      "Ты видишь дни, ты видишь всё на свете, ты слышишь эту музыку вдали, весь этот путь от жизни и до смерти, весь этот стон и дым вокруг земли, а кто нас встретит, где нас нынче встретят, покуда страх нам душу не сковал… \n",
      "\n",
      "\"А мы с тобой проснёмся поутру\" - Юлия Долгановских\n",
      "а мы с тобой проснёмся поутру\n",
      "агу и ты ответишь мне агу\n",
      "врагу покажется мы потеряли разум\n",
      "а мы с тобою только родились\n",
      "и пеленой беспомощная жизнь\n",
      "опутывает нас обоих разом\n",
      "\n",
      "агу прости а где а кто а я\n",
      "а ты а мы и в полнокровный полдень\n",
      "отряхивая солнце с мутных глаз\n",
      "мы оба ночь рождения не вспомним\n",
      "\n",
      "лишь вглядываясь в камешки ручья\n",
      "в неверном лунном свете еле-еле\n",
      "переставляя непорядок фраз\n",
      "рука к руке на берегу постели\n",
      "\n",
      "увидим беспощадный силуэт\n",
      "удвоенный расплывчатою речью\n",
      "агу прости а где то силы нет\n",
      "то воли просыпаться вовсе лечь и\n",
      "\n",
      "молчать во все последние слова\n",
      "смотреть во все потерянные рифмы\n",
      "и новых не желая узнавать\n",
      "беспомощных как смерть неизъяснимых \n",
      "\n",
      "\"Я ей не дочь\" - Лана Юрина\n",
      "А впрочем, я всё знаю наизусть –\n",
      "про жизнь и смерть, про детство в Кутаиси. \n",
      "\n",
      "\"Долгая дорога\" - Владимир Остапенко\n",
      "То, что в прошлом было между нами,\n",
      "Я до смерти не смогу забыть. \n",
      "\n",
      "\"Строки о красоте\" - Елена Печерская 2\n",
      "Красоту нужно видеть в простом,\n",
      "Чтобы жизнь, что кипит за холстом,\n",
      "Проступала полней на мольберте,\n",
      "Неподвластная тленью и смерти... \n",
      "\n",
      "\"Ветер ветви дрожащие гладит\" - Хубулава Григорий Геннадьевич\n",
      "В песне осени, в огненных пятнах\n",
      "Перед долгой, тяжёлой зимой\n",
      "Предвкушенье победы внезапной\n",
      "Вековечнее смерти самой. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Введите слово или словосочетание:')\n",
    "request = input()\n",
    "the_search(request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
